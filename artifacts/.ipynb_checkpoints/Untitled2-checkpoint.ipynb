{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "530072f4-0438-49b7-a027-dcc877838a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as snb\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout\n",
    "import time\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input\n",
    "from utils import save_history  \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import mplfinance as mpf\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da4efc6e-249e-441a-9e73-af790931b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"GBPUSD_M15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23b454ea-4bcb-47ca-a412-cbbc594370b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['close'], columns=['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ddc7d7-95aa-4dec-a5c6-ce098970357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.37433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.37422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.37496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.37484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.37573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62219</th>\n",
       "      <td>1.24435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62220</th>\n",
       "      <td>1.24382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62221</th>\n",
       "      <td>1.24380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62222</th>\n",
       "      <td>1.24370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62223</th>\n",
       "      <td>1.24453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62224 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         close\n",
       "0      1.37433\n",
       "1      1.37422\n",
       "2      1.37496\n",
       "3      1.37484\n",
       "4      1.37573\n",
       "...        ...\n",
       "62219  1.24435\n",
       "62220  1.24382\n",
       "62221  1.24380\n",
       "62222  1.24370\n",
       "62223  1.24453\n",
       "\n",
       "[62224 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "094d80b8-d1a9-40d1-82c1-44b0ea86fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Behdad\\AppData\\Local\\Temp\\ipykernel_24380\\4015728933.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data1[f'close_lag_{i}'] = data1['close'].shift(i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>close_lag_1</th>\n",
       "      <th>close_lag_2</th>\n",
       "      <th>close_lag_3</th>\n",
       "      <th>close_lag_4</th>\n",
       "      <th>close_lag_5</th>\n",
       "      <th>close_lag_6</th>\n",
       "      <th>close_lag_7</th>\n",
       "      <th>close_lag_8</th>\n",
       "      <th>close_lag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>close_lag_91</th>\n",
       "      <th>close_lag_92</th>\n",
       "      <th>close_lag_93</th>\n",
       "      <th>close_lag_94</th>\n",
       "      <th>close_lag_95</th>\n",
       "      <th>close_lag_96</th>\n",
       "      <th>close_lag_97</th>\n",
       "      <th>close_lag_98</th>\n",
       "      <th>close_lag_99</th>\n",
       "      <th>close_lag_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>1.37284</td>\n",
       "      <td>1.37313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "      <td>1.37422</td>\n",
       "      <td>1.37433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>1.37284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "      <td>1.37422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.37296</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37296</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37589</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.37290</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37296</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37509</td>\n",
       "      <td>1.37589</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62219</th>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24351</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "      <td>1.24734</td>\n",
       "      <td>1.24766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62220</th>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "      <td>1.24734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62221</th>\n",
       "      <td>1.24380</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62222</th>\n",
       "      <td>1.24370</td>\n",
       "      <td>1.24380</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24875</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62223</th>\n",
       "      <td>1.24453</td>\n",
       "      <td>1.24370</td>\n",
       "      <td>1.24380</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24896</td>\n",
       "      <td>1.24875</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62124 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         close  close_lag_1  close_lag_2  close_lag_3  close_lag_4  \\\n",
       "100    1.37289      1.37264      1.37282      1.37248      1.37293   \n",
       "101    1.37295      1.37289      1.37264      1.37282      1.37248   \n",
       "102    1.37296      1.37295      1.37289      1.37264      1.37282   \n",
       "103    1.37295      1.37296      1.37295      1.37289      1.37264   \n",
       "104    1.37290      1.37295      1.37296      1.37295      1.37289   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "62219  1.24435      1.24347      1.24309      1.24234      1.24160   \n",
       "62220  1.24382      1.24435      1.24347      1.24309      1.24234   \n",
       "62221  1.24380      1.24382      1.24435      1.24347      1.24309   \n",
       "62222  1.24370      1.24380      1.24382      1.24435      1.24347   \n",
       "62223  1.24453      1.24370      1.24380      1.24382      1.24435   \n",
       "\n",
       "       close_lag_5  close_lag_6  close_lag_7  close_lag_8  close_lag_9  ...  \\\n",
       "100        1.37246      1.37281      1.37279      1.37284      1.37313  ...   \n",
       "101        1.37293      1.37246      1.37281      1.37279      1.37284  ...   \n",
       "102        1.37248      1.37293      1.37246      1.37281      1.37279  ...   \n",
       "103        1.37282      1.37248      1.37293      1.37246      1.37281  ...   \n",
       "104        1.37264      1.37282      1.37248      1.37293      1.37246  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "62219      1.24207      1.24359      1.24359      1.24382      1.24351  ...   \n",
       "62220      1.24160      1.24207      1.24359      1.24359      1.24382  ...   \n",
       "62221      1.24234      1.24160      1.24207      1.24359      1.24359  ...   \n",
       "62222      1.24309      1.24234      1.24160      1.24207      1.24359  ...   \n",
       "62223      1.24347      1.24309      1.24234      1.24160      1.24207  ...   \n",
       "\n",
       "       close_lag_91  close_lag_92  close_lag_93  close_lag_94  close_lag_95  \\\n",
       "100         1.37648       1.37618       1.37601       1.37576       1.37562   \n",
       "101         1.37622       1.37648       1.37618       1.37601       1.37576   \n",
       "102         1.37602       1.37622       1.37648       1.37618       1.37601   \n",
       "103         1.37589       1.37602       1.37622       1.37648       1.37618   \n",
       "104         1.37509       1.37589       1.37602       1.37622       1.37648   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "62219       1.24781       1.24792       1.24820       1.24755       1.24650   \n",
       "62220       1.24816       1.24781       1.24792       1.24820       1.24755   \n",
       "62221       1.24869       1.24816       1.24781       1.24792       1.24820   \n",
       "62222       1.24875       1.24869       1.24816       1.24781       1.24792   \n",
       "62223       1.24896       1.24875       1.24869       1.24816       1.24781   \n",
       "\n",
       "       close_lag_96  close_lag_97  close_lag_98  close_lag_99  close_lag_100  \n",
       "100         1.37573       1.37484       1.37496       1.37422        1.37433  \n",
       "101         1.37562       1.37573       1.37484       1.37496        1.37422  \n",
       "102         1.37576       1.37562       1.37573       1.37484        1.37496  \n",
       "103         1.37601       1.37576       1.37562       1.37573        1.37484  \n",
       "104         1.37618       1.37601       1.37576       1.37562        1.37573  \n",
       "...             ...           ...           ...           ...            ...  \n",
       "62219       1.24683       1.24662       1.24726       1.24734        1.24766  \n",
       "62220       1.24650       1.24683       1.24662       1.24726        1.24734  \n",
       "62221       1.24755       1.24650       1.24683       1.24662        1.24726  \n",
       "62222       1.24820       1.24755       1.24650       1.24683        1.24662  \n",
       "62223       1.24792       1.24820       1.24755       1.24650        1.24683  \n",
       "\n",
       "[62124 rows x 101 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lags = 100\n",
    "data1 = df\n",
    "for i in range(1, num_lags + 1):\n",
    "    data1[f'close_lag_{i}'] = data1['close'].shift(i)\n",
    "    \n",
    "data1 = data1.dropna()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad2ec8d4-36b5-42df-bd69-ce645913fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1['close']\n",
    "X = data1.drop(['close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a05e8edb-34a6-48b7-ac3c-824c1f2d4296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_lag_1</th>\n",
       "      <th>close_lag_2</th>\n",
       "      <th>close_lag_3</th>\n",
       "      <th>close_lag_4</th>\n",
       "      <th>close_lag_5</th>\n",
       "      <th>close_lag_6</th>\n",
       "      <th>close_lag_7</th>\n",
       "      <th>close_lag_8</th>\n",
       "      <th>close_lag_9</th>\n",
       "      <th>close_lag_10</th>\n",
       "      <th>...</th>\n",
       "      <th>close_lag_91</th>\n",
       "      <th>close_lag_92</th>\n",
       "      <th>close_lag_93</th>\n",
       "      <th>close_lag_94</th>\n",
       "      <th>close_lag_95</th>\n",
       "      <th>close_lag_96</th>\n",
       "      <th>close_lag_97</th>\n",
       "      <th>close_lag_98</th>\n",
       "      <th>close_lag_99</th>\n",
       "      <th>close_lag_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>1.37284</td>\n",
       "      <td>1.37313</td>\n",
       "      <td>1.37324</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "      <td>1.37422</td>\n",
       "      <td>1.37433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>1.37284</td>\n",
       "      <td>1.37313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "      <td>1.37422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>1.37284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "      <td>1.37496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.37296</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>1.37279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37589</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "      <td>1.37484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37296</td>\n",
       "      <td>1.37295</td>\n",
       "      <td>1.37289</td>\n",
       "      <td>1.37264</td>\n",
       "      <td>1.37282</td>\n",
       "      <td>1.37248</td>\n",
       "      <td>1.37293</td>\n",
       "      <td>1.37246</td>\n",
       "      <td>1.37281</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37509</td>\n",
       "      <td>1.37589</td>\n",
       "      <td>1.37602</td>\n",
       "      <td>1.37622</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>1.37618</td>\n",
       "      <td>1.37601</td>\n",
       "      <td>1.37576</td>\n",
       "      <td>1.37562</td>\n",
       "      <td>1.37573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62219</th>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24351</td>\n",
       "      <td>1.24331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "      <td>1.24734</td>\n",
       "      <td>1.24766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62220</th>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24351</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "      <td>1.24734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62221</th>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "      <td>1.24726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62222</th>\n",
       "      <td>1.24380</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24875</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "      <td>1.24662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62223</th>\n",
       "      <td>1.24370</td>\n",
       "      <td>1.24380</td>\n",
       "      <td>1.24382</td>\n",
       "      <td>1.24435</td>\n",
       "      <td>1.24347</td>\n",
       "      <td>1.24309</td>\n",
       "      <td>1.24234</td>\n",
       "      <td>1.24160</td>\n",
       "      <td>1.24207</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24896</td>\n",
       "      <td>1.24875</td>\n",
       "      <td>1.24869</td>\n",
       "      <td>1.24816</td>\n",
       "      <td>1.24781</td>\n",
       "      <td>1.24792</td>\n",
       "      <td>1.24820</td>\n",
       "      <td>1.24755</td>\n",
       "      <td>1.24650</td>\n",
       "      <td>1.24683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62124 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       close_lag_1  close_lag_2  close_lag_3  close_lag_4  close_lag_5  \\\n",
       "100        1.37264      1.37282      1.37248      1.37293      1.37246   \n",
       "101        1.37289      1.37264      1.37282      1.37248      1.37293   \n",
       "102        1.37295      1.37289      1.37264      1.37282      1.37248   \n",
       "103        1.37296      1.37295      1.37289      1.37264      1.37282   \n",
       "104        1.37295      1.37296      1.37295      1.37289      1.37264   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "62219      1.24347      1.24309      1.24234      1.24160      1.24207   \n",
       "62220      1.24435      1.24347      1.24309      1.24234      1.24160   \n",
       "62221      1.24382      1.24435      1.24347      1.24309      1.24234   \n",
       "62222      1.24380      1.24382      1.24435      1.24347      1.24309   \n",
       "62223      1.24370      1.24380      1.24382      1.24435      1.24347   \n",
       "\n",
       "       close_lag_6  close_lag_7  close_lag_8  close_lag_9  close_lag_10  ...  \\\n",
       "100        1.37281      1.37279      1.37284      1.37313       1.37324  ...   \n",
       "101        1.37246      1.37281      1.37279      1.37284       1.37313  ...   \n",
       "102        1.37293      1.37246      1.37281      1.37279       1.37284  ...   \n",
       "103        1.37248      1.37293      1.37246      1.37281       1.37279  ...   \n",
       "104        1.37282      1.37248      1.37293      1.37246       1.37281  ...   \n",
       "...            ...          ...          ...          ...           ...  ...   \n",
       "62219      1.24359      1.24359      1.24382      1.24351       1.24331  ...   \n",
       "62220      1.24207      1.24359      1.24359      1.24382       1.24351  ...   \n",
       "62221      1.24160      1.24207      1.24359      1.24359       1.24382  ...   \n",
       "62222      1.24234      1.24160      1.24207      1.24359       1.24359  ...   \n",
       "62223      1.24309      1.24234      1.24160      1.24207       1.24359  ...   \n",
       "\n",
       "       close_lag_91  close_lag_92  close_lag_93  close_lag_94  close_lag_95  \\\n",
       "100         1.37648       1.37618       1.37601       1.37576       1.37562   \n",
       "101         1.37622       1.37648       1.37618       1.37601       1.37576   \n",
       "102         1.37602       1.37622       1.37648       1.37618       1.37601   \n",
       "103         1.37589       1.37602       1.37622       1.37648       1.37618   \n",
       "104         1.37509       1.37589       1.37602       1.37622       1.37648   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "62219       1.24781       1.24792       1.24820       1.24755       1.24650   \n",
       "62220       1.24816       1.24781       1.24792       1.24820       1.24755   \n",
       "62221       1.24869       1.24816       1.24781       1.24792       1.24820   \n",
       "62222       1.24875       1.24869       1.24816       1.24781       1.24792   \n",
       "62223       1.24896       1.24875       1.24869       1.24816       1.24781   \n",
       "\n",
       "       close_lag_96  close_lag_97  close_lag_98  close_lag_99  close_lag_100  \n",
       "100         1.37573       1.37484       1.37496       1.37422        1.37433  \n",
       "101         1.37562       1.37573       1.37484       1.37496        1.37422  \n",
       "102         1.37576       1.37562       1.37573       1.37484        1.37496  \n",
       "103         1.37601       1.37576       1.37562       1.37573        1.37484  \n",
       "104         1.37618       1.37601       1.37576       1.37562        1.37573  \n",
       "...             ...           ...           ...           ...            ...  \n",
       "62219       1.24683       1.24662       1.24726       1.24734        1.24766  \n",
       "62220       1.24650       1.24683       1.24662       1.24726        1.24734  \n",
       "62221       1.24755       1.24650       1.24683       1.24662        1.24726  \n",
       "62222       1.24820       1.24755       1.24650       1.24683        1.24662  \n",
       "62223       1.24792       1.24820       1.24755       1.24650        1.24683  \n",
       "\n",
       "[62124 rows x 100 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e688b097-5d73-49e2-a102-1ff33135c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_normalized = scaler_X.fit_transform(X)\n",
    "y_normalized = scaler_y.fit_transform(pd.DataFrame(y, columns=['close']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "309bed4b-f177-4cc6-91bc-5b5792dc5b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96985583],\n",
       "       [0.97003058],\n",
       "       [0.97005971],\n",
       "       ...,\n",
       "       [0.59388379],\n",
       "       [0.59359254],\n",
       "       [0.5960099 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized\n",
    "y_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b87bbb68-96af-446f-aa4a-8294180d561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(25, return_sequences=True, input_shape=(1, 100)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(25, return_sequences=False),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "768adc55-5aa2-49d3-b872-556fab7dc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "700a3b3a-0970-4be2-8d35-793c80c1487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ec6b06d-99d9-4fb2-a62c-c6e0dd908efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "y_test_reshaped = y_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1c1b2ce-3715-4b73-bcda-3d89163b3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12425, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reshaped.shape\n",
    "y_test_reshaped.shape\n",
    "X_test_reshaped.shape\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb6c9cd2-6219-4089-8949-ac2380d38b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0687 - val_loss: 4.6222e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 1.2043e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 2.1513e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 1.3649e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.6827e-04 - val_loss: 1.0891e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4224e-04 - val_loss: 2.5484e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2883e-04 - val_loss: 1.4866e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 7.6217e-05 - val_loss: 1.0680e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 7.0884e-05 - val_loss: 1.8688e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 6.1313e-05 - val_loss: 1.6895e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.6837e-05 - val_loss: 7.1467e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.9336e-05 - val_loss: 1.2687e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.2007e-05 - val_loss: 8.8045e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1520e-05 - val_loss: 7.6123e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.4261e-05 - val_loss: 5.4985e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1129e-05 - val_loss: 8.9787e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.9362e-05 - val_loss: 1.1319e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.8604e-05 - val_loss: 1.5106e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.7129e-05 - val_loss: 1.4874e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.6888e-05 - val_loss: 2.7635e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 4.6353e-05 - val_loss: 1.2466e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.6372e-05 - val_loss: 1.9780e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.8244e-05 - val_loss: 2.1899e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.5297e-05 - val_loss: 4.6582e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.5797e-05 - val_loss: 1.8289e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.4041e-05 - val_loss: 7.6310e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4.3911e-05 - val_loss: 1.0342e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.3079e-05 - val_loss: 6.2298e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.4284e-05 - val_loss: 5.8660e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.3563e-05 - val_loss: 1.9236e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.3823e-05 - val_loss: 1.9370e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 4.1346e-05 - val_loss: 1.4851e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.3295e-05 - val_loss: 9.9063e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.2836e-05 - val_loss: 5.5634e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.2137e-05 - val_loss: 5.2604e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.4862e-05 - val_loss: 2.7630e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0263e-05 - val_loss: 5.2911e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.1636e-05 - val_loss: 8.4200e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.1057e-05 - val_loss: 7.1186e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0140e-05 - val_loss: 1.7579e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0574e-05 - val_loss: 4.0125e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.9398e-05 - val_loss: 1.2944e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9995e-05 - val_loss: 9.3972e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9411e-05 - val_loss: 6.7111e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0116e-05 - val_loss: 8.2234e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0589e-05 - val_loss: 5.8731e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.9699e-05 - val_loss: 8.4724e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9214e-05 - val_loss: 8.8821e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9939e-05 - val_loss: 1.3060e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0176e-05 - val_loss: 8.5750e-06\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not History",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_history2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+w\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[0;32m      3\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train_reshaped, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test_reshaped))\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not History"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    with open(\"train_history2.txt\", '+w') as file: \n",
    "        history = model.fit(X_train_reshaped, y_train_reshaped, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test_reshaped))\n",
    "        file.write(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a6cc269-67f7-4a2d-bb5d-15dff233519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.5726e-06\n",
      "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test_reshaped, y_test_reshaped)\n",
    "\n",
    "predictions = model.predict(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b796a52e-ef67-4cb4-a439-efddea2c7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.576240032145919e-06\n",
      "RMSE: 0.0029285218169147927\n",
      "MAE: 0.00250037044894489\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test_reshaped, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_reshaped, predictions)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "100f5b3b-79bd-4909-af34-f192e8f3598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./products/lstm_model_v3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"./products/lstm_model_v3.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "068b46e6-f74b-4feb-9c67-c007f70cf48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./products/scaler_X.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler_y, './products/scaler_y.pkl')\n",
    "joblib.dump(scaler_X, './products/scaler_X.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb5d63-5952-4b74-880d-1e704545256b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
